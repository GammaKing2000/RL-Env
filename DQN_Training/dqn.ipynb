{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e329e3",
   "metadata": {},
   "source": [
    "# Training Grow-R Environment with DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4cb19",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a42104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "\n",
    "# Add the parent directory to the path to allow for package imports\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(notebook_dir, '..')))\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common import logger\n",
    "from training_utils import SaveOnIntervalCallback, visualise_training_logs\n",
    "from plantos_env import PlantOSEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08f94a",
   "metadata": {},
   "source": [
    "## Define paths for saving models and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2060e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run = \"1M\"\n",
    "\n",
    "# Define paths for saving models and logs\n",
    "MODEL_DIR = os.path.join(\"DQN_Training/models\", training_run)\n",
    "LOG_DIR = os.path.join(\"DQN_Training/logs\", training_run)\n",
    "TENSORBOARD_LOG_DIR = \"DQN_Training/logs\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83532e86",
   "metadata": {},
   "source": [
    "## Initialising the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d3efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:788: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='rgb_array' that is not in the possible render_modes ([]).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "n_envs = 4\n",
    "env_kwargs = {\n",
    "    'grid_size': 21,\n",
    "    'num_plants': 20,\n",
    "    'num_obstacles': 12,\n",
    "    'lidar_range': 6,\n",
    "    'lidar_channels': 32,\n",
    "    'observation_mode': 'grid',\n",
    "    'thirsty_plant_prob': 0.5\n",
    "}\n",
    "\n",
    "# Create vectorized environment using the registered environment ID\n",
    "env = make_vec_env('PlantOS-v0', n_envs=n_envs, env_kwargs=env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05afbe9",
   "metadata": {},
   "source": [
    "## Initialising the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6347d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to DQN_Training/logs\\1M\n"
     ]
    }
   ],
   "source": [
    "# 2. Define the model\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=5e-5,  # Slightly smaller learning rate for more stable updates\n",
    "    buffer_size=100000,  # Increased buffer size from 100000\n",
    "    learning_starts=10000, # Increase learning starts to fill the buffer a bit more\n",
    "    batch_size=32,\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    gradient_steps=1,\n",
    "    target_update_interval=1000,\n",
    "    exploration_fraction=0.2,  # Explore for a bit longer\n",
    "    exploration_final_eps=0.01, # Exploit more at the end\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(net_arch=[256, 256])\n",
    "    #tensorboard_log=TENSORBOARD_LOG_DIR\n",
    ")\n",
    "\n",
    "# Log the training\n",
    "new_logger = logger.configure(LOG_DIR, [\"stdout\", \"csv\"])\n",
    "model.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2922c",
   "metadata": {},
   "source": [
    "## Setting up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8223fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.num_plants to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_plants` for environment variables or `env.get_wrapper_attr('num_plants')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.R_GOAL to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.R_GOAL` for environment variables or `env.get_wrapper_attr('R_GOAL')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "num_plants = env.get_attr('num_plants')[0]\n",
    "r_goal = env.get_attr('R_GOAL')[0]\n",
    "reward_threshold = r_goal * num_plants * 0.8\n",
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=reward_threshold, verbose=1)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    env,\n",
    "    callback_after_eval=stop_callback,\n",
    "    best_model_save_path=MODEL_DIR,\n",
    "    log_path=LOG_DIR,\n",
    "    eval_freq=100000,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "save_interval = 100000\n",
    "save_callback = SaveOnIntervalCallback(save_interval, MODEL_DIR)\n",
    "combined_callbacks = [eval_callback, save_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c2e14",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acdfaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DQN training with Stable Baselines3...\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -2.92e+03 |\n",
      "|    exploration_rate | 0.901     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 3493      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 4000      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -2.98e+03 |\n",
      "|    exploration_rate | 0.802     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 3519      |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 8000      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -3.16e+03 |\n",
      "|    exploration_rate | 0.703     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 3078      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.59      |\n",
      "|    n_updates        | 124       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -3.54e+03 |\n",
      "|    exploration_rate | 0.604     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 2746      |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total_timesteps  | 16000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 4.66      |\n",
      "|    n_updates        | 374       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -3.66e+03 |\n",
      "|    exploration_rate | 0.505     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 2539      |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 20000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 0.899     |\n",
      "|    n_updates        | 624       |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -4e+03   |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 2413     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 5e-05    |\n",
      "|    loss             | 3.83     |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -4.38e+03 |\n",
      "|    exploration_rate | 0.307     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 2326      |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 28000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 2.68      |\n",
      "|    n_updates        | 1124      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -4.69e+03 |\n",
      "|    exploration_rate | 0.208     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 2256      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 32000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3.26      |\n",
      "|    n_updates        | 1374      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -5e+03   |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 2204     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 5e-05    |\n",
      "|    loss             | 3.48     |\n",
      "|    n_updates        | 1624     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -5.31e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 2171      |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total_timesteps  | 40000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.9       |\n",
      "|    n_updates        | 1874      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -6.58e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 2139      |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total_timesteps  | 44000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.8       |\n",
      "|    n_updates        | 2124      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -6.76e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 2108      |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total_timesteps  | 48000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 9.1       |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -7.17e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 2082      |\n",
      "|    time_elapsed     | 24        |\n",
      "|    total_timesteps  | 52000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 2.92      |\n",
      "|    n_updates        | 2624      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -7.6e+03 |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 2060     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 56000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 5e-05    |\n",
      "|    loss             | 5.28     |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -7.42e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 2041      |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total_timesteps  | 60000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 2.32      |\n",
      "|    n_updates        | 3124      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -7.7e+03 |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 2039     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 64000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 5e-05    |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.46e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 2042      |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total_timesteps  | 68000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 7.28      |\n",
      "|    n_updates        | 3624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.26e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 2037      |\n",
      "|    time_elapsed     | 35        |\n",
      "|    total_timesteps  | 72000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 7.45      |\n",
      "|    n_updates        | 3874      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.16e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 2036      |\n",
      "|    time_elapsed     | 37        |\n",
      "|    total_timesteps  | 76000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 10.9      |\n",
      "|    n_updates        | 4124      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -8e+03   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 2041     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 5e-05    |\n",
      "|    loss             | 4.31     |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.08e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 2039      |\n",
      "|    time_elapsed     | 41        |\n",
      "|    total_timesteps  | 84000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 7.73      |\n",
      "|    n_updates        | 4624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.22e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 2041      |\n",
      "|    time_elapsed     | 43        |\n",
      "|    total_timesteps  | 88000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 7.08      |\n",
      "|    n_updates        | 4874      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.07e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 2039      |\n",
      "|    time_elapsed     | 45        |\n",
      "|    total_timesteps  | 92000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 4.38      |\n",
      "|    n_updates        | 5124      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.41e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 2039      |\n",
      "|    time_elapsed     | 47        |\n",
      "|    total_timesteps  | 96000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3.68      |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "Saving model to DQN_Training/models\\1M\\model_100000.zip\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.28e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 2035      |\n",
      "|    time_elapsed     | 49        |\n",
      "|    total_timesteps  | 100000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.07      |\n",
      "|    n_updates        | 5624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.55e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 2032      |\n",
      "|    time_elapsed     | 51        |\n",
      "|    total_timesteps  | 104000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 4.14      |\n",
      "|    n_updates        | 5874      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -8.8e+03 |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 2029     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 108000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 5e-05    |\n",
      "|    loss             | 3.78     |\n",
      "|    n_updates        | 6124     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -8.85e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 2025      |\n",
      "|    time_elapsed     | 55        |\n",
      "|    total_timesteps  | 112000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 7.04      |\n",
      "|    n_updates        | 6374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.01e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 2020      |\n",
      "|    time_elapsed     | 57        |\n",
      "|    total_timesteps  | 116000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 6.47      |\n",
      "|    n_updates        | 6624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.04e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 120       |\n",
      "|    fps              | 2014      |\n",
      "|    time_elapsed     | 59        |\n",
      "|    total_timesteps  | 120000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3.69      |\n",
      "|    n_updates        | 6874      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.35e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 124       |\n",
      "|    fps              | 2012      |\n",
      "|    time_elapsed     | 61        |\n",
      "|    total_timesteps  | 124000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 6.22      |\n",
      "|    n_updates        | 7124      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.28e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 128       |\n",
      "|    fps              | 2008      |\n",
      "|    time_elapsed     | 63        |\n",
      "|    total_timesteps  | 128000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 4.68      |\n",
      "|    n_updates        | 7374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.22e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 132       |\n",
      "|    fps              | 1999      |\n",
      "|    time_elapsed     | 66        |\n",
      "|    total_timesteps  | 132000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.9       |\n",
      "|    n_updates        | 7624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.12e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 136       |\n",
      "|    fps              | 1992      |\n",
      "|    time_elapsed     | 68        |\n",
      "|    total_timesteps  | 136000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3.23      |\n",
      "|    n_updates        | 7874      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.48e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 140       |\n",
      "|    fps              | 1987      |\n",
      "|    time_elapsed     | 70        |\n",
      "|    total_timesteps  | 140000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3         |\n",
      "|    n_updates        | 8124      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.18e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 144       |\n",
      "|    fps              | 1985      |\n",
      "|    time_elapsed     | 72        |\n",
      "|    total_timesteps  | 144000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 2.95      |\n",
      "|    n_updates        | 8374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.34e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 148       |\n",
      "|    fps              | 1982      |\n",
      "|    time_elapsed     | 74        |\n",
      "|    total_timesteps  | 148000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 2.97      |\n",
      "|    n_updates        | 8624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.45e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 152       |\n",
      "|    fps              | 1979      |\n",
      "|    time_elapsed     | 76        |\n",
      "|    total_timesteps  | 152000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 0.0399    |\n",
      "|    n_updates        | 8874      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.67e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 156       |\n",
      "|    fps              | 1975      |\n",
      "|    time_elapsed     | 78        |\n",
      "|    total_timesteps  | 156000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 6.78      |\n",
      "|    n_updates        | 9124      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -1.04e+04 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 160       |\n",
      "|    fps              | 1972      |\n",
      "|    time_elapsed     | 81        |\n",
      "|    total_timesteps  | 160000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.9       |\n",
      "|    n_updates        | 9374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -1.04e+04 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 164       |\n",
      "|    fps              | 1970      |\n",
      "|    time_elapsed     | 83        |\n",
      "|    total_timesteps  | 164000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 24.2      |\n",
      "|    n_updates        | 9624      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.81e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 168       |\n",
      "|    fps              | 1967      |\n",
      "|    time_elapsed     | 85        |\n",
      "|    total_timesteps  | 168000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.9       |\n",
      "|    n_updates        | 9874      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -9.9e+03 |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 1965     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 172000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 5e-05    |\n",
      "|    loss             | 8.85     |\n",
      "|    n_updates        | 10124    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.99e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 176       |\n",
      "|    fps              | 1961      |\n",
      "|    time_elapsed     | 89        |\n",
      "|    total_timesteps  | 176000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 8.88      |\n",
      "|    n_updates        | 10374     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -1.03e+04 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 180       |\n",
      "|    fps              | 1957      |\n",
      "|    time_elapsed     | 91        |\n",
      "|    total_timesteps  | 180000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3         |\n",
      "|    n_updates        | 10624     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -1.01e+04 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 184       |\n",
      "|    fps              | 1955      |\n",
      "|    time_elapsed     | 94        |\n",
      "|    total_timesteps  | 184000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 5.91      |\n",
      "|    n_updates        | 10874     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.83e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 188       |\n",
      "|    fps              | 1953      |\n",
      "|    time_elapsed     | 96        |\n",
      "|    total_timesteps  | 188000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3.27      |\n",
      "|    n_updates        | 11124     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -1.01e+04 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 192       |\n",
      "|    fps              | 1952      |\n",
      "|    time_elapsed     | 98        |\n",
      "|    total_timesteps  | 192000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 3.38      |\n",
      "|    n_updates        | 11374     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.71e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 196       |\n",
      "|    fps              | 1954      |\n",
      "|    time_elapsed     | 100       |\n",
      "|    total_timesteps  | 196000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 2.99      |\n",
      "|    n_updates        | 11624     |\n",
      "-----------------------------------\n",
      "Saving model to DQN_Training/models\\1M\\model_200000.zip\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1e+03     |\n",
      "|    ep_rew_mean      | -9.71e+03 |\n",
      "|    exploration_rate | 0.01      |\n",
      "| time/               |           |\n",
      "|    episodes         | 200       |\n",
      "|    fps              | 1956      |\n",
      "|    time_elapsed     | 102       |\n",
      "|    total_timesteps  | 200000    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 5e-05     |\n",
      "|    loss             | 0.627     |\n",
      "|    n_updates        | 11874     |\n",
      "-----------------------------------\n",
      "DQN Training Finished.\n",
      "Total timesteps trained: 200000\n",
      "This is the avg reward: -4900.00 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting DQN training with Stable Baselines3...\")\n",
    "model.learn(\n",
    "    total_timesteps=200000, # 200,000\n",
    "    callback=combined_callbacks\n",
    ")\n",
    "print(\"DQN Training Finished.\")\n",
    "print(f\"Total timesteps trained: {model.num_timesteps}\")\n",
    "\n",
    "# Evaluate the trained model\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "print(f\"This is the avg reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# 5. Save the final model\n",
    "model.save(os.path.join(MODEL_DIR, f\"dqn_plantos_final_model-{training_run}\"))\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_a3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
