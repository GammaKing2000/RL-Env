{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e329e3",
   "metadata": {},
   "source": [
    "# Training Grow-R Environment with PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4cb19",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a42104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "\n",
    "# Add the parent directory to the path to allow for package imports\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(notebook_dir, '..')))\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from stable_baselines3.common import logger\n",
    "from collections import OrderedDict\n",
    "from training_utils import SaveOnIntervalCallback, visualise_training_logs\n",
    "from plantos_env import PlantOSEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08f94a",
   "metadata": {},
   "source": [
    "## Define paths for saving models and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2060e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run = \"1M\"\n",
    "\n",
    "MODEL_DIR = os.path.join(\"PPO_Training/models\", training_run)\n",
    "LOG_DIR = os.path.join(\"PPO_Training/logs\", training_run)\n",
    "TENSORBOARD_LOG_DIR = \"PPO_Training/logs\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be3c59",
   "metadata": {},
   "source": [
    "## Setting PPO Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505f6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Hyperparameters\n",
    "config = OrderedDict([('batch_size', 64),\n",
    "            ('clip_range', 0.18),\n",
    "            ('ent_coef', 0.0),\n",
    "            ('gae_lambda', 0.95),\n",
    "            ('gamma', 0.999),\n",
    "            ('learning_rate', 0.0003),\n",
    "            ('n_epochs', 10),\n",
    "            ('n_steps', 2048),\n",
    "            ('n_timesteps', 200000.0),\n",
    "            ('normalize', True),\n",
    "            ('policy', 'MlpPolicy'),\n",
    "            ('policy_kwargs', dict(net_arch=[256, 256])),\n",
    "            ('normalize_kwargs', {'norm_obs': True, 'norm_reward': False})])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83532e86",
   "metadata": {},
   "source": [
    "## Initialising the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d3efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:788: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='rgb_array' that is not in the possible render_modes ([]).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "n_envs = 4\n",
    "env_kwargs = {\n",
    "    'grid_size': 21,\n",
    "    'num_plants': 20,\n",
    "    'num_obstacles': 12,\n",
    "    'lidar_range': 6,\n",
    "    'lidar_channels': 32,\n",
    "    'observation_mode': 'grid',\n",
    "    'thirsty_plant_prob': 0.5\n",
    "}\n",
    "\n",
    "# Create vectorized environment using the registered environment ID\n",
    "env = make_vec_env('PlantOS-v0', n_envs=n_envs, env_kwargs=env_kwargs)\n",
    "if config['normalize']:\n",
    "    env = VecNormalize(env, norm_obs=config['normalize_kwargs']['norm_obs'], norm_reward=config['normalize_kwargs']['norm_reward'], clip_obs=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05afbe9",
   "metadata": {},
   "source": [
    "## Initialising the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb6347d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to PPO_Training/logs\\1M\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "        config['policy'],\n",
    "        env,\n",
    "        device='cpu',\n",
    "        verbose=1,\n",
    "        learning_rate=float(config['learning_rate']),\n",
    "        batch_size=int(config['batch_size']),\n",
    "        gamma=float(config['gamma']),\n",
    "        clip_range=config['clip_range'],\n",
    "        ent_coef=config['ent_coef'],\n",
    "        gae_lambda=config['gae_lambda'],\n",
    "        n_epochs=config['n_epochs'],\n",
    "        n_steps=config['n_steps'],\n",
    "        #tensorboard_log=TENSORBOARD_LOG_DIR\n",
    "    )\n",
    "\n",
    "# Log the training\n",
    "new_logger = logger.configure(LOG_DIR, [\"stdout\", \"csv\"])\n",
    "model.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2922c",
   "metadata": {},
   "source": [
    "## Setting up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8223fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.num_plants to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_plants` for environment variables or `env.get_wrapper_attr('num_plants')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\mohda\\miniconda3\\envs\\rl_a3\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.R_GOAL to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.R_GOAL` for environment variables or `env.get_wrapper_attr('R_GOAL')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "num_plants = env.get_attr('num_plants')[0]\n",
    "r_goal = env.get_attr('R_GOAL')[0]\n",
    "reward_threshold = r_goal * num_plants * 0.8\n",
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=reward_threshold, verbose=1)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    env,\n",
    "    callback_after_eval=stop_callback,\n",
    "    best_model_save_path=MODEL_DIR,\n",
    "    log_path=LOG_DIR,\n",
    "    eval_freq=100000,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "save_interval = 100000\n",
    "save_callback = SaveOnIntervalCallback(save_interval, MODEL_DIR)\n",
    "combined_callbacks = [eval_callback, save_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c2e14",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3acdfaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PPO training with Stable Baselines3...\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 2241      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 8192      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -3.16e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1326        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008851167 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.00163    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 4.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.99e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1193        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009234533 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 4.58e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.97e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1132        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009592298 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.99e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1101        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008268782 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.97e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010491328 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -3e+03       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1071         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092036445 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.18         |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 909          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    value_loss           | 2.31e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -2.97e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1064       |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01097046 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.18       |\n",
      "|    entropy_loss         | -1.57      |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 925        |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    value_loss           | 2.71e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.87e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1057        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010557561 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 984         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1049        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010349926 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 560         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.87e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1045        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013946414 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 491         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 2.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1036        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010236949 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Saving model to PPO_Training/models\\1M\\model_100000.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.84e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1029        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013017882 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 875         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 2.23e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.78e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1025        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011516182 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 661         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.76e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1022        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010192219 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 2.04e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.69e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1020        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011228921 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 698         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1015        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009831161 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 468         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.63e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1013        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011213166 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 795         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.64e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1011        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010055175 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 977         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 2.47e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.6e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1011        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009589252 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 746         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.65e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1011        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009865055 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -2.59e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1011       |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00996989 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.18       |\n",
      "|    entropy_loss         | -1.56      |\n",
      "|    explained_variance   | 0.805      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.38e+03   |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 2.65e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -2.56e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1011       |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01306352 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.18       |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 403        |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    value_loss           | 1.99e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.52e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1011        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011213166 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "Saving model to PPO_Training/models\\1M\\model_200000.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.53e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1011        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010142275 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.18        |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 928         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "PPO Training Finished.\n",
      "Total timesteps trained: 204800\n",
      "This is the avg reward: -6006.51 +/- 4779.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting PPO training with Stable Baselines3...\")\n",
    "model.learn(\n",
    "    total_timesteps=config['n_timesteps'], # 1 Million\n",
    "    callback=combined_callbacks\n",
    ")\n",
    "print(\"PPO Training Finished.\")\n",
    "print(f\"Total timesteps trained: {model.num_timesteps}\")\n",
    "\n",
    "# Evaluate the trained model\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "print(f\"This is the avg reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# 5. Save the final model\n",
    "model.save(os.path.join(MODEL_DIR, f\"ppo_plantos_final_model-{training_run}\"))\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_a3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
